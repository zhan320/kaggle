{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7945e9a82d7512fbf96246d9bbc29cd2f106c1a4a9cf54c9563dadf10f2237d4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import os to read system directory\n",
    "import os\n",
    "\n",
    "# import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, BatchNormalization, MaxPooling2D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current working directory\n",
    "path = os.getcwd()\n",
    "\n",
    "# read the training data\n",
    "train_data_full = pd.read_csv(path+'/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42000 entries, 0 to 41999\nColumns: 785 entries, label to pixel783\ndtypes: int64(785)\nmemory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "# get an overview of the training data\n",
    "train_data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the data type is int64, here we need to convert them into float32.\n",
    "train_data_full = train_data_full.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the features and target from the training data\n",
    "X_train_full = np.array(train_data_full.iloc[:,1:])\n",
    "y_train_full = np.array(train_data_full.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(42000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Notice that each image is 28 pixels in height and 28 pixels in width. To train the data using Keras, we need to reshape each image into a 3-dimentional array (28, 28, 1)\n",
    "X_train_full = X_train_full.reshape(X_train_full.shape[0], 28, 28, 1)\n",
    "print(X_train_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "X_train = X_train_full / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels to one-hot vectors\n",
    "y_train = to_categorical(y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN model for image classification problem\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=X_train.shape[1:]))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 13, 13, 32)        128       \n_________________________________________________________________\ndropout (Dropout)            (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 5, 5, 32)          128       \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 5, 5, 32)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 800)               0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               102528    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 128)               512       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 114,154\nTrainable params: 113,770\nNon-trainable params: 384\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get an overview of the network\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "525/525 [==============================] - 42s 79ms/step - loss: 0.3053 - accuracy: 0.9049 - val_loss: 0.0993 - val_accuracy: 0.9707\n",
      "Epoch 2/30\n",
      "525/525 [==============================] - 39s 75ms/step - loss: 0.1149 - accuracy: 0.9643 - val_loss: 0.0583 - val_accuracy: 0.9823\n",
      "Epoch 3/30\n",
      "525/525 [==============================] - 33s 64ms/step - loss: 0.0886 - accuracy: 0.9722 - val_loss: 0.0462 - val_accuracy: 0.9867\n",
      "Epoch 4/30\n",
      "525/525 [==============================] - 38s 72ms/step - loss: 0.0758 - accuracy: 0.9760 - val_loss: 0.0389 - val_accuracy: 0.9880\n",
      "Epoch 5/30\n",
      "525/525 [==============================] - 53s 101ms/step - loss: 0.0657 - accuracy: 0.9784 - val_loss: 0.0332 - val_accuracy: 0.9896\n",
      "Epoch 6/30\n",
      "525/525 [==============================] - 50s 96ms/step - loss: 0.0584 - accuracy: 0.9815 - val_loss: 0.0361 - val_accuracy: 0.9894\n",
      "Epoch 7/30\n",
      "525/525 [==============================] - 58s 110ms/step - loss: 0.0548 - accuracy: 0.9823 - val_loss: 0.0333 - val_accuracy: 0.9902\n",
      "Epoch 8/30\n",
      "525/525 [==============================] - 57s 108ms/step - loss: 0.0497 - accuracy: 0.9842 - val_loss: 0.0345 - val_accuracy: 0.9900\n",
      "Epoch 9/30\n",
      "525/525 [==============================] - 58s 110ms/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 0.0322 - val_accuracy: 0.9915\n",
      "Epoch 10/30\n",
      "525/525 [==============================] - 57s 109ms/step - loss: 0.0443 - accuracy: 0.9855 - val_loss: 0.0361 - val_accuracy: 0.9905\n",
      "Epoch 11/30\n",
      "525/525 [==============================] - 57s 108ms/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 0.0341 - val_accuracy: 0.9895\n",
      "Epoch 12/30\n",
      "525/525 [==============================] - 58s 110ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0328 - val_accuracy: 0.9901\n",
      "Epoch 13/30\n",
      "525/525 [==============================] - 56s 107ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.0309 - val_accuracy: 0.9914\n",
      "Epoch 14/30\n",
      "525/525 [==============================] - 56s 108ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 0.0318 - val_accuracy: 0.9910\n",
      "Epoch 15/30\n",
      "525/525 [==============================] - 52s 99ms/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.0337 - val_accuracy: 0.9913\n",
      "Epoch 16/30\n",
      "525/525 [==============================] - 58s 111ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.0298 - val_accuracy: 0.9917\n",
      "Epoch 17/30\n",
      "525/525 [==============================] - 56s 107ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.0353 - val_accuracy: 0.9908\n",
      "Epoch 18/30\n",
      "525/525 [==============================] - 55s 104ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.0330 - val_accuracy: 0.9908\n",
      "Epoch 19/30\n",
      "525/525 [==============================] - 53s 102ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 0.0335 - val_accuracy: 0.9918\n",
      "Epoch 20/30\n",
      "525/525 [==============================] - 55s 104ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0315 - val_accuracy: 0.9921\n",
      "Epoch 21/30\n",
      "525/525 [==============================] - 54s 104ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0298 - val_accuracy: 0.9929\n",
      "Epoch 22/30\n",
      "525/525 [==============================] - 54s 103ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 0.0264 - val_accuracy: 0.9930\n",
      "Epoch 23/30\n",
      "525/525 [==============================] - 53s 102ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0310 - val_accuracy: 0.9921\n",
      "Epoch 24/30\n",
      "525/525 [==============================] - 53s 100ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.0284 - val_accuracy: 0.9927\n",
      "Epoch 25/30\n",
      "525/525 [==============================] - 55s 104ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0317 - val_accuracy: 0.9913\n",
      "Epoch 26/30\n",
      "525/525 [==============================] - 54s 102ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0308 - val_accuracy: 0.9920\n",
      "Epoch 27/30\n",
      "525/525 [==============================] - 56s 106ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0284 - val_accuracy: 0.9933\n",
      "Epoch 28/30\n",
      "525/525 [==============================] - 54s 102ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0303 - val_accuracy: 0.9920\n",
      "Epoch 29/30\n",
      "525/525 [==============================] - 53s 102ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.0332 - val_accuracy: 0.9914\n",
      "Epoch 30/30\n",
      "525/525 [==============================] - 54s 103ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.0352 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3d0f48>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the testing data\n",
    "test_data_full = pd.read_csv(path+'/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into float32 type\n",
    "test_data_full = test_data_full.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "X_test_full = np.array(test_data_full) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape the testing images into 3-dimentional arrays\n",
    "X_test = X_test_full.reshape(X_test_full.shape[0], 28, 28, 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the result for the testing images\n",
    "y_test = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(y_test, columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ImageId\n",
    "Id = pd.DataFrame(np.arange(1, y_test.shape[0]+1), columns=['ImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the result as a csv file\n",
    "pd.concat([Id, res], axis=1).to_csv('predictions.csv', index=False)"
   ]
  }
 ]
}